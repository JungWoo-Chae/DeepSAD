{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                logical_gpus = tf.config.experimental.list_logical_devices(\n",
    "                    'GPU')\n",
    "                logging.info(\n",
    "                    \"Detect {} Physical GPUs, {} Logical GPUs.\".format(\n",
    "                        len(gpus), len(logical_gpus)))\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            logging.info(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[[1],[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1],[2]])\n",
    "b=np.array([[1],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(c,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.Variable(tf.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_class = tuple([0])\n",
    "known_outlier_classes = (1,3)\n",
    "n_classes = 2  # 0: normal, 1: outlier\n",
    "normal_classes = tuple(normal_class)\n",
    "outlier_classes = list(range(0, 10))\n",
    "for i in normal_class: outlier_classes.remove(i) \n",
    "outlier_classes = tuple(outlier_classes)\n",
    "\n",
    "ratio_known_normal= 0.0\n",
    "ratio_known_outlier= 0.01\n",
    "ratio_pollution = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, 5, 6, 7, 8, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x) for  x in outlier_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_semisupervised_setting(labels, normal_classes, outlier_classes, known_outlier_classes,\n",
    "                                  ratio_known_normal, ratio_known_outlier, ratio_pollution):\n",
    "    \"\"\"\n",
    "    Create a semi-supervised data setting. \n",
    "    :param labels: np.array with labels of all dataset samples\n",
    "    :param normal_classes: tuple with normal class labels\n",
    "    :param outlier_classes: tuple with anomaly class labels\n",
    "    :param known_outlier_classes: tuple with known (labeled) anomaly class labels\n",
    "    :param ratio_known_normal: the desired ratio of known (labeled) normal samples\n",
    "    :param ratio_known_outlier: the desired ratio of known (labeled) anomalous samples\n",
    "    :param ratio_pollution: the desired pollution ratio of the unlabeled data with unknown (unlabeled) anomalies.\n",
    "    :return: tuple with list of sample indices, list of original labels, and list of semi-supervised labels\n",
    "    \"\"\"\n",
    "    idx_normal = np.argwhere(np.isin(labels, normal_classes)).flatten()\n",
    "    idx_outlier = np.argwhere(np.isin(labels, outlier_classes)).flatten()\n",
    "    idx_known_outlier_candidates = np.argwhere(np.isin(labels, known_outlier_classes)).flatten()\n",
    "\n",
    "    n_normal = len(idx_normal)\n",
    "\n",
    "    # Solve system of linear equations to obtain respective number of samples\n",
    "    a = np.array([[1, 1, 0, 0],\n",
    "                  [(1-ratio_known_normal), -ratio_known_normal, -ratio_known_normal, -ratio_known_normal],\n",
    "                  [-ratio_known_outlier, -ratio_known_outlier, -ratio_known_outlier, (1-ratio_known_outlier)],\n",
    "                  [0, -ratio_pollution, (1-ratio_pollution), 0]])\n",
    "    b = np.array([n_normal, 0, 0, 0])\n",
    "    x = np.linalg.solve(a, b)\n",
    "\n",
    "    # Get number of samples\n",
    "    n_known_normal = int(x[0])\n",
    "    n_unlabeled_normal = int(x[1])\n",
    "    n_unlabeled_outlier = int(x[2])\n",
    "    n_known_outlier = int(x[3])\n",
    "\n",
    "    # Sample indices\n",
    "    perm_normal = np.random.permutation(n_normal)\n",
    "    perm_outlier = np.random.permutation(len(idx_outlier))\n",
    "    perm_known_outlier = np.random.permutation(len(idx_known_outlier_candidates))\n",
    "\n",
    "    idx_known_normal = idx_normal[perm_normal[:n_known_normal]].tolist()\n",
    "    idx_unlabeled_normal = idx_normal[perm_normal[n_known_normal:n_known_normal+n_unlabeled_normal]].tolist()\n",
    "    idx_unlabeled_outlier = idx_outlier[perm_outlier[:n_unlabeled_outlier]].tolist()\n",
    "    idx_known_outlier = idx_known_outlier_candidates[perm_known_outlier[:n_known_outlier]].tolist()\n",
    "\n",
    "    # Get original class labels\n",
    "    labels_known_normal = labels[idx_known_normal].tolist()\n",
    "    labels_unlabeled_normal = labels[idx_unlabeled_normal].tolist()\n",
    "    labels_unlabeled_outlier = labels[idx_unlabeled_outlier].tolist()\n",
    "    labels_known_outlier = labels[idx_known_outlier].tolist()\n",
    "\n",
    "    # Get semi-supervised setting labels\n",
    "    semi_labels_known_normal = np.ones(n_known_normal).astype(np.int32).tolist()\n",
    "    semi_labels_unlabeled_normal = np.zeros(n_unlabeled_normal).astype(np.int32).tolist()\n",
    "    semi_labels_unlabeled_outlier = np.zeros(n_unlabeled_outlier).astype(np.int32).tolist()\n",
    "    semi_labels_known_outlier = (-np.ones(n_known_outlier).astype(np.int32)).tolist()\n",
    "    \n",
    "#     print(len(labels_known_normal))\n",
    "#     print(len(semi_labels_known_normal))\n",
    "#     print(len(labels_unlabeled_normal))\n",
    "#     print(len(semi_labels_unlabeled_normal))\n",
    "#     print(len(labels_unlabeled_outlier))\n",
    "#     print(len(semi_labels_unlabeled_outlier))\n",
    "#     print(len(labels_known_outlier))\n",
    "#     print(len(semi_labels_known_outlier))\n",
    "#     print()\n",
    "#     print(len(idx_known_outlier_candidates))\n",
    "    \n",
    "    \n",
    "    # Create final lists\n",
    "    list_idx = idx_known_normal + idx_unlabeled_normal + idx_unlabeled_outlier + idx_known_outlier\n",
    "    list_labels = labels_known_normal + labels_unlabeled_normal + labels_unlabeled_outlier + labels_known_outlier\n",
    "    list_semi_labels = (semi_labels_known_normal + semi_labels_unlabeled_normal + semi_labels_unlabeled_outlier\n",
    "                        + semi_labels_known_outlier)\n",
    "\n",
    "    return list_idx, list_labels, list_semi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, ll, semi_targets = create_semisupervised_setting(y_train, normal_classes,\n",
    "                                                             outlier_classes, known_outlier_classes,\n",
    "                                                             ratio_known_normal, ratio_known_outlier, ratio_pollution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train[idx], y_train[idx], semi_targets))\n",
    "train_data = train_data.shuffle(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label, semi_label):\n",
    "    return tf.cast(image, tf.float32) / 255., label, semi_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.batch(8)\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 28, 28), dtype=float32, numpy=\n",
       " array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=uint8, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)>,\n",
       " <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tf.constant([[1.,2.,3.,4.,5.],[1.,1.,1.,1.,1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([2., 3., 4., 5., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+tf.reduce_sum(b,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([2., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 4., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where((b>3)&(b<5),b,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
